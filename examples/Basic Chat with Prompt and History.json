{
  "id": "956f0b67-9c18-4275-8bf5-dd4024590b82",
  "data": {
    "nodes": [
      {
        "width": 384,
        "height": 629,
        "id": "ChatOpenAI-qdmsI",
        "type": "genericNode",
        "position": {
          "x": 241.3279963280445,
          "y": -486.8439112212181
        },
        "data": {
          "type": "ChatOpenAI",
          "node": {
            "template": {
              "callbacks": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "callbacks",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "langchain.callbacks.base.BaseCallbackHandler",
                "list": true
              },
              "cache": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "cache",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "bool",
                "list": false
              },
              "client": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "client",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "Any",
                "list": false
              },
              "max_retries": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "value": 6,
                "password": false,
                "name": "max_retries",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "int",
                "list": false
              },
              "max_tokens": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": true,
                "name": "max_tokens",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "int",
                "list": false,
                "value": ""
              },
              "metadata": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "metadata",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "dict",
                "list": false
              },
              "model_kwargs": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "model_kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "dict",
                "list": false
              },
              "model_name": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "gpt-3.5-turbo",
                "password": false,
                "options": [
                  "gpt-3.5-turbo-0613",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-16k-0613",
                  "gpt-3.5-turbo-16k",
                  "gpt-4-0613",
                  "gpt-4-32k-0613",
                  "gpt-4",
                  "gpt-4-32k"
                ],
                "name": "model_name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": true
              },
              "n": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "value": 1,
                "password": false,
                "name": "n",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "int",
                "list": false
              },
              "openai_api_base": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": false,
                "dynamic": false,
                "info": "\nThe base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.\n",
                "type": "str",
                "list": false
              },
              "openai_api_key": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "",
                "password": true,
                "name": "openai_api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "openai_organization": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "openai_organization",
                "display_name": "OpenAI Organization",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "openai_proxy": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "openai_proxy",
                "display_name": "OpenAI Proxy",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "request_timeout": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "request_timeout",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "float",
                "list": false,
                "value": 60
              },
              "streaming": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "value": false,
                "password": false,
                "name": "streaming",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "bool",
                "list": false
              },
              "tags": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "tags",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": true
              },
              "temperature": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": 0.7,
                "password": false,
                "name": "temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "float",
                "list": false
              },
              "tiktoken_model_name": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "tiktoken_model_name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "verbose": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "value": false,
                "password": false,
                "name": "verbose",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "bool",
                "list": false
              },
              "_type": "ChatOpenAI"
            },
            "description": "`OpenAI` Chat large language models API.",
            "base_classes": [
              "ChatOpenAI",
              "BaseChatModel",
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "display_name": "ChatOpenAI",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/integrations/openai"
          },
          "id": "ChatOpenAI-qdmsI",
          "value": null
        },
        "selected": true,
        "dragging": false,
        "positionAbsolute": {
          "x": 241.3279963280445,
          "y": -486.8439112212181
        }
      },
      {
        "width": 384,
        "height": 577,
        "id": "ConversationBufferMemory-frtJG",
        "type": "genericNode",
        "position": {
          "x": 240.68758111624516,
          "y": 172.4355109349313
        },
        "data": {
          "type": "ConversationBufferMemory",
          "node": {
            "template": {
              "chat_memory": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "chat_memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "BaseChatMessageHistory",
                "list": false
              },
              "ai_prefix": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "value": "AI",
                "password": false,
                "name": "ai_prefix",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "human_prefix": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "value": "Human",
                "password": false,
                "name": "human_prefix",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "input_key": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "",
                "password": false,
                "name": "input_key",
                "advanced": false,
                "dynamic": false,
                "info": "The variable to be used as Chat Input when more than one variable is available.",
                "type": "str",
                "list": false
              },
              "memory_key": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "history",
                "password": false,
                "name": "memory_key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "output_key": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "",
                "password": false,
                "name": "output_key",
                "advanced": false,
                "dynamic": false,
                "info": "The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)",
                "type": "str",
                "list": false
              },
              "return_messages": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "return_messages",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "bool",
                "list": false
              },
              "_type": "ConversationBufferMemory"
            },
            "description": "Buffer for storing conversation memory.",
            "base_classes": [
              "ConversationBufferMemory",
              "BaseChatMemory",
              "BaseMemory"
            ],
            "display_name": "ConversationBufferMemory",
            "documentation": "https://python.langchain.com/docs/modules/memory/how_to/buffer"
          },
          "id": "ConversationBufferMemory-frtJG",
          "value": null
        },
        "selected": false,
        "positionAbsolute": {
          "x": 240.68758111624516,
          "y": 172.4355109349313
        },
        "dragging": false
      },
      {
        "width": 384,
        "height": 469,
        "id": "PromptTemplate-mrNIG",
        "type": "genericNode",
        "position": {
          "x": 249.637230371315,
          "y": 756.3732210160607
        },
        "data": {
          "type": "PromptTemplate",
          "node": {
            "template": {
              "output_parser": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "output_parser",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "BaseOutputParser",
                "list": false
              },
              "input_variables": {
                "required": true,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "input_variables",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": true,
                "value": [
                  "history",
                  "text"
                ]
              },
              "partial_variables": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "password": false,
                "name": "partial_variables",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "dict",
                "list": false
              },
              "template": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": true,
                "password": false,
                "name": "template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "prompt",
                "list": false,
                "value": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n\n{history}\nHuman: {text}\nAI:"
              },
              "template_format": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "value": "f-string",
                "password": false,
                "name": "template_format",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "validate_template": {
                "required": false,
                "placeholder": "",
                "show": false,
                "multiline": false,
                "value": true,
                "password": false,
                "name": "validate_template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "bool",
                "list": false
              },
              "_type": "PromptTemplate",
              "history": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": true,
                "value": "",
                "password": false,
                "name": "history",
                "display_name": "history",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "text": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": true,
                "value": "",
                "password": false,
                "name": "text",
                "display_name": "text",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              }
            },
            "description": "A prompt template for a language model.",
            "base_classes": [
              "StringPromptTemplate",
              "PromptTemplate",
              "BasePromptTemplate"
            ],
            "name": "",
            "display_name": "PromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/",
            "custom_fields": {
              "": [
                "history",
                "text"
              ],
              "template": [
                "history",
                "text"
              ]
            },
            "output_types": [],
            "field_formatters": {},
            "beta": false,
            "error": null
          },
          "id": "PromptTemplate-mrNIG"
        },
        "selected": false,
        "positionAbsolute": {
          "x": 249.637230371315,
          "y": 756.3732210160607
        },
        "dragging": false
      },
      {
        "width": 384,
        "height": 339,
        "id": "LLMChain-Pvm9x",
        "type": "genericNode",
        "position": {
          "x": 1299.7208072540463,
          "y": 634.671457752373
        },
        "data": {
          "type": "LLMChain",
          "node": {
            "template": {
              "code": {
                "dynamic": true,
                "required": true,
                "placeholder": "",
                "show": false,
                "multiline": true,
                "value": "from langflow import CustomComponent\nfrom langchain.chains import LLMChain\nfrom typing import Optional, Union, Callable\nfrom langflow.field_typing import PromptTemplate, BaseLanguageModel, BaseMemory, Chain\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: PromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                "password": false,
                "name": "code",
                "advanced": false,
                "type": "code",
                "list": false
              },
              "_type": "CustomComponent",
              "llm": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "BaseLanguageModel",
                "list": false
              },
              "memory": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "BaseMemory",
                "list": false
              },
              "prompt": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "prompt",
                "display_name": "Prompt",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "PromptTemplate",
                "list": false
              }
            },
            "description": "Chain to run queries against LLMs",
            "base_classes": [
              "Chain",
              "Callable"
            ],
            "display_name": "LLMChain",
            "custom_fields": {
              "llm": null,
              "memory": null,
              "prompt": null
            },
            "output_types": [
              "LLMChain"
            ],
            "documentation": "",
            "beta": true,
            "error": null
          },
          "id": "LLMChain-Pvm9x"
        },
        "positionAbsolute": {
          "x": 1299.7208072540463,
          "y": 634.671457752373
        }
      }
    ],
    "edges": [
      {
        "source": "ConversationBufferMemory-frtJG",
        "sourceHandle": "{œbaseClassesœ:[œConversationBufferMemoryœ,œBaseChatMemoryœ,œBaseMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-frtJGœ}",
        "target": "LLMChain-Pvm9x",
        "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}",
        "data": {
          "targetHandle": {
            "fieldName": "memory",
            "id": "LLMChain-Pvm9x",
            "inputTypes": null,
            "type": "BaseMemory"
          },
          "sourceHandle": {
            "baseClasses": [
              "ConversationBufferMemory",
              "BaseChatMemory",
              "BaseMemory"
            ],
            "dataType": "ConversationBufferMemory",
            "id": "ConversationBufferMemory-frtJG"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ConversationBufferMemory-frtJG{œbaseClassesœ:[œConversationBufferMemoryœ,œBaseChatMemoryœ,œBaseMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-frtJGœ}-LLMChain-Pvm9x{œfieldNameœ:œmemoryœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}"
      },
      {
        "source": "PromptTemplate-mrNIG",
        "sourceHandle": "{œbaseClassesœ:[œStringPromptTemplateœ,œPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-mrNIGœ}",
        "target": "LLMChain-Pvm9x",
        "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œPromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "prompt",
            "id": "LLMChain-Pvm9x",
            "inputTypes": null,
            "type": "PromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "StringPromptTemplate",
              "PromptTemplate",
              "BasePromptTemplate"
            ],
            "dataType": "PromptTemplate",
            "id": "PromptTemplate-mrNIG"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-PromptTemplate-mrNIG{œbaseClassesœ:[œStringPromptTemplateœ,œPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-mrNIGœ}-LLMChain-Pvm9x{œfieldNameœ:œpromptœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œPromptTemplateœ}"
      },
      {
        "source": "ChatOpenAI-qdmsI",
        "sourceHandle": "{œbaseClassesœ:[œChatOpenAIœ,œBaseChatModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-qdmsIœ}",
        "target": "LLMChain-Pvm9x",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "LLMChain-Pvm9x",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "ChatOpenAI",
              "BaseChatModel",
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "dataType": "ChatOpenAI",
            "id": "ChatOpenAI-qdmsI"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ChatOpenAI-qdmsI{œbaseClassesœ:[œChatOpenAIœ,œBaseChatModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-qdmsIœ}-LLMChain-Pvm9x{œfieldNameœ:œllmœ,œidœ:œLLMChain-Pvm9xœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      }
    ],
    "viewport": {
      "x": -8.68396403367342,
      "y": 256.83423473981316,
      "zoom": 0.4060094549734929
    }
  },
  "description": "A simple chat with a custom prompt template and conversational memory buffer",
  "name": "Basic Chat with Prompt and History"
}